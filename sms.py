# -*- coding: utf-8 -*-
"""SMS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SvVrTS0KEzvser5bq81OUT8S6bLZSP9R
"""
import os
os.system('pip install -r requirements_sms.txt')
# WORD2VEC
def word2vector():
  import os
  os.system('pip install gensim')
  os.system('pip install nltk')
  from gensim.models import Word2Vec
  import nltk
  import itertools
  import math
  import gensim.downloader as api
  model = api.load('word2vec-google-news-300')
  from nltk.corpus import stopwords
  nltk.download('stopwords')
  stop_words=stopwords.words('english')
  sent_a_list = input('Enter the first list of sentences.').split('.')
  sent_b_list = input('Enter the second list of sentences').split('.')
  assert len(sent_a_list) == len(sent_b_list), "Both the lists should contain equal number of sentences."
  for sent_a,sent_b in zip(sent_a_list[0:len(sent_a_list)-1],sent_b_list[0:len(sent_b_list)-1]):
    sent_a=sent_a.lower().split()
    sent_b=sent_b.lower().split()
    sent_a = [w for w in sent_a if w not in stop_words ]
    sent_b = [w for w in sent_b if w not in stop_words ]
    distance = model.wmdistance(sent_a,sent_b)
    sim=math.exp(-distance)
    print(' The SMS score for Word2Vec is : {}'.format(sim))

def spacy_score():
  import os
  os.system('pip install -U spacy')
  import spacy
  import itertools
  os.system('python -m spacy download en_core_web_md')
  import en_core_web_md
  nlp = en_core_web_md.load()
  # import wmd
  import math
  sent_a_list = input('Enter the first list of sentences : ').split('.')
  sent_b_list = input('Enter the second list of sentences : ').split('.')
  assert len(sent_a_list) == len(sent_b_list), "Both the lists should contain equal number of sentences."
  for sent_a,sent_b in zip(sent_a_list[0:len(sent_a_list)-1],sent_b_list[0:len(sent_b_list)-1]):
    doc1 = nlp(sent_a)
    doc2 = nlp(sent_b)
    sim= (doc1.similarity(doc2))
    print(' The SMS score for SpaCy is : {}'.format(math.exp(-sim)))

def glove_score():
  import os
  os.system('pip install word-mover-distance')
  os.system('wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip')
  os.system('unzip glove.6B.zip')
  import numpy as np
  import math
  import itertools
  import word_mover_distance.model as model
  model = model.WordEmbedding(model_fn="/glove.6B/glove.6B.300d.txt")
  embeddings_dict = {}
  with open("glove.6B.300d.txt", 'r') as f:
    for line in f:
      values = line.split()
      word = values[0]
      vector = np.asarray(values[1:], "float32")
      embeddings_dict[word] = vector
  sent_a_list=input('Enter the first list of sentences').split('.')
  sent_b_list=input('Enter the second list of sentence').split('.')
  assert len(sent_a_list) == len(sent_b_list), "Both the lists should contain equal number of sentences."
  for sent_a,sent_b in zip(sent_a_list[0:len(sent_a_list)-1],sent_b_list[0:len(sent_b_list)-1]):
    sent_a_embd=np.zeros((len(sent_a),300))
    sent_b_embd=np.zeros((len(sent_b),300))
    for index,a in enumerate(sent_a.split(' ')):
      sent_a_embd[index,:]=embeddings_dict[a]
    sent_a_embd=(np.sum(sent_a_embd,axis=0))/len(sent_a)
    for index,b in enumerate(sent_b.split(' ')):
      sent_b_embd[index,:]=embeddings_dict[b]
    sent_b_embd=(np.sum(sent_b_embd,axis=0))/len(sent_b)
    wmdistance = model.wmdistance(sent_a, sent_b)
    sims=math.exp(-wmdistance)
    print(' The SMS score for Glove is : {}'.format(sims))

if __name__=='__main__':
  print(' Select the type of embeddings you want to use : ')
  print(' Press 1 for Word2Vec \n Press 2 for SpaCy (web_md) \n Press 3 for Glove Embeddings (300d) \n')
  choice=int(input('Enter your choice : '))
  if choice == 1 :
    word2vector()
  elif choice == 2 :
    spacy_score()
  elif choice == 3 :
    glove_score()
  else :
    print('Incorrect Choice')



